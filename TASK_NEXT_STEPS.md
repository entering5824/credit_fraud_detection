# CÃ´ng viá»‡c Tiáº¿p theo - Week 2 (Minh PhÃº)

## Tá»•ng quan

Theo WORKFLOW.md, Ä‘Ã¢y lÃ  cÃ´ng viá»‡c tiáº¿p theo cho pháº§n **Modeling setup** (Minh PhÃº) trong Week 2.

## Má»¥c tiÃªu

1. Train cÃ¡c ensemble models Ä‘áº§y Ä‘á»§ vá»›i parameters tá»‘i Æ°u
2. LÆ°u models Ä‘Ã£ train vÃ o thÆ° má»¥c `models/`
3. ÄÃ¡nh giÃ¡ models trÃªn validation set
4. Táº¡o báº£ng metrics vÃ  visualizations

## CÃ´ng viá»‡c cáº§n hoÃ n thÃ nh

### âœ… ÄÃ£ hoÃ n thÃ nh (tÃ­ch há»£p tá»« codebase chÃ­nh)

- Module `src/models.py` Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ functions:
  - `train_random_forest()` - Train Random Forest
  - `train_adaboost()` - Train AdaBoost  
  - `train_xgboost()` - Train XGBoost
  - `save_model()` - LÆ°u model
  - `load_model()` - Load model
  - `evaluate_model_performance()` - ÄÃ¡nh giÃ¡ model

- Module `src/evaluate.py` Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ functions:
  - `calculate_metrics()` - TÃ­nh Precision, Recall, F1, AUC
  - `get_metrics_dict()` - Láº¥y metrics dáº¡ng dictionary
  - `print_metrics()` - In metrics
  - `plot_confusion_matrix()` - Váº½ confusion matrix
  - `plot_roc_curve()` - Váº½ ROC curve
  - `plot_metrics_comparison()` - So sÃ¡nh metrics
  - `export_metrics_to_csv()` - Xuáº¥t metrics ra CSV

- Notebook `02_Model_Training.ipynb` Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t vá»›i:
  - Sections Ä‘á»ƒ train 3 models
  - Evaluation vá»›i evaluate.py
  - Visualization metrics comparison
  - LÆ°u models

### ğŸ“‹ Checklist cÃ´ng viá»‡c cáº§n lÃ m

#### 1. Cháº¡y Notebook 02 Ä‘á»ƒ Train Models

```python
# Má»Ÿ vÃ  cháº¡y notebook: notebooks/02_Model_Training.ipynb
# Notebook sáº½:
# - Load vÃ  preprocess data
# - Train Random Forest, AdaBoost, XGBoost
# - ÄÃ¡nh giÃ¡ trÃªn validation set
# - LÆ°u models vÃ o models/
```

**CÃ¡c bÆ°á»›c:**
- [ ] Má»Ÿ `notebooks/02_Model_Training.ipynb`
- [ ] Cháº¡y táº¥t cáº£ cells tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
- [ ] Kiá»ƒm tra models Ä‘Ã£ Ä‘Æ°á»£c train thÃ nh cÃ´ng
- [ ] Kiá»ƒm tra models Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o `models/`:
  - `models/random_forest.pkl`
  - `models/adaboost.pkl`
  - `models/xgboost.pkl`

#### 2. Tá»‘i Æ°u Parameters (Optional nhÆ°ng khuyáº¿n nghá»‹)

Náº¿u muá»‘n cáº£i thiá»‡n performance, cÃ³ thá»ƒ thá»­ cÃ¡c parameters khÃ¡c:

**Random Forest:**
```python
rf_model = train_random_forest(
    X_train, y_train,
    n_estimators=300,  # TÄƒng sá»‘ trees
    max_depth=20,      # TÄƒng depth
    class_weight=class_weights,
    random_state=42
)
```

**AdaBoost:**
```python
ada_model = train_adaboost(
    X_train, y_train,
    n_estimators=150,   # TÄƒng sá»‘ estimators
    learning_rate=0.3,  # Äiá»u chá»‰nh learning rate
    random_state=42
)
```

**XGBoost:**
```python
xgb_model = train_xgboost(
    X_train, y_train,
    n_estimators=200,   # TÄƒng sá»‘ rounds
    max_depth=8,        # TÄƒng depth
    learning_rate=0.05, # Giáº£m learning rate
    scale_pos_weight=scale_pos_weight,
    random_state=42
)
```

#### 3. ÄÃ¡nh giÃ¡ Models trÃªn Validation Set

Notebook 02 Ä‘Ã£ cÃ³ code Ä‘á»ƒ Ä‘Ã¡nh giÃ¡, nhÆ°ng cÃ³ thá»ƒ thÃªm:

```python
# Sá»­ dá»¥ng evaluate.py Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t
from src.evaluate import evaluate_model, get_metrics_dict

# ÄÃ¡nh giÃ¡ tá»«ng model
for model_name, model in trained_models.items():
    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    # TÃ­nh metrics
    metrics = get_metrics_dict(y_val, y_pred, y_pred_proba, model_name)
    
    # In metrics
    print_metrics(y_val, y_pred, y_pred_proba, model_name)
```

#### 4. Táº¡o Báº£ng Metrics

Notebook 02 Ä‘Ã£ táº¡o báº£ng metrics, nhÆ°ng cÃ³ thá»ƒ export ra CSV:

```python
from src.evaluate import export_metrics_to_csv

# Collect all metrics
all_metrics = []
for model_name in trained_models.keys():
    y_pred = model_predictions[model_name]
    y_pred_proba = model_probabilities[model_name]
    metrics = get_metrics_dict(y_val, y_pred, y_pred_proba, model_name)
    all_metrics.append(metrics)

# Export to CSV
export_metrics_to_csv(all_metrics, 'results/metrics_validation.csv')
```

#### 5. Váº½ Bar Chart So sÃ¡nh Hiá»‡u nÄƒng

Notebook 02 Ä‘Ã£ cÃ³ visualization, nhÆ°ng cÃ³ thá»ƒ lÆ°u:

```python
from src.evaluate import plot_metrics_comparison

# Plot vÃ  lÆ°u
fig = plot_metrics_comparison(
    all_metrics, 
    save_path='results/metrics_comparison_validation.png',
    figsize=(14, 7)
)
plt.show()
```

#### 6. LÆ°u Confusion Matrices vÃ  ROC Curves

CÃ³ thá»ƒ thÃªm vÃ o notebook 02:

```python
from src.evaluate import plot_confusion_matrix, plot_roc_curve

# LÆ°u confusion matrices
for model_name in trained_models.keys():
    y_pred = model_predictions[model_name]
    save_path = f'results/confusion_matrices/{model_name.replace(" ", "_")}_validation.png'
    plot_confusion_matrix(y_val, y_pred, model_name, save_path=save_path)

# LÆ°u ROC curves
from src.evaluate import compare_models_roc

y_true_dict = {name: y_val for name in model_probabilities.keys()}
fig = compare_models_roc(
    y_true_dict, 
    model_probabilities, 
    save_path='results/roc_curves_validation.png'
)
plt.show()
```

## HÆ°á»›ng dáº«n sá»­ dá»¥ng

### CÃ¡ch 1: Sá»­ dá»¥ng Notebook (Khuyáº¿n nghá»‹)

1. Má»Ÿ `notebooks/02_Model_Training.ipynb`
2. Cháº¡y táº¥t cáº£ cells
3. Models sáº½ Ä‘Æ°á»£c train vÃ  lÆ°u tá»± Ä‘á»™ng
4. Metrics sáº½ Ä‘Æ°á»£c hiá»ƒn thá»‹ vÃ  cÃ³ thá»ƒ export

### CÃ¡ch 2: Sá»­ dá»¥ng Script Python

CÃ³ thá»ƒ táº¡o script `train_all_models.py`:

```python
from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).parent))

from src.data_preprocessing import scale_features, split_data, get_class_weights
from src.models import train_random_forest, train_adaboost, train_xgboost, save_model
from src.evaluate import get_metrics_dict, print_metrics, export_metrics_to_csv

# Load vÃ  preprocess data
# ... (code tá»« notebook)

# Train models
# ... (code tá»« notebook)

# Save models
# ... (code tá»« notebook)
```

## Files cáº§n kiá»ƒm tra sau khi hoÃ n thÃ nh

- [ ] `models/random_forest.pkl` - Random Forest model
- [ ] `models/adaboost.pkl` - AdaBoost model
- [ ] `models/xgboost.pkl` - XGBoost model
- [ ] `models/scaler.pkl` - Scaler (Ä‘Ã£ cÃ³ tá»« notebook 01)
- [ ] `results/metrics_validation.csv` - Metrics table (optional)
- [ ] `results/metrics_comparison_validation.png` - Comparison chart (optional)

## LÆ°u Ã½ quan trá»ng

1. **Sá»­ dá»¥ng Validation Set**: ÄÃ¡nh giÃ¡ trÃªn validation set, khÃ´ng pháº£i test set
2. **Test Set**: Giá»¯ test set cho notebook 03 (final evaluation)
3. **Class Weights**: ÄÃ£ Ä‘Æ°á»£c tÃ­nh vÃ  sá»­ dá»¥ng trong training
4. **Scale Pos Weight**: XGBoost cáº§n `scale_pos_weight` Ä‘á»ƒ handle imbalance
5. **Random State**: Sá»­ dá»¥ng `random_state=42` Ä‘á»ƒ Ä‘áº£m báº£o reproducibility

## Káº¿t quáº£ mong Ä‘á»£i

Sau khi hoÃ n thÃ nh, báº¡n sáº½ cÃ³:

1. âœ… 3 models Ä‘Ã£ Ä‘Æ°á»£c train vÃ  lÆ°u
2. âœ… Metrics comparison cho táº¥t cáº£ models
3. âœ… Visualizations (confusion matrices, ROC curves)
4. âœ… Models sáºµn sÃ ng cho notebook 03 vÃ  application

## CÃ´ng viá»‡c tiáº¿p theo (sau khi hoÃ n thÃ nh)

Sau khi train xong models, cÃ´ng viá»‡c tiáº¿p theo:

1. **Notebook 03** (Pháº¡m TÃº): Evaluation & Comparison cuá»‘i cÃ¹ng trÃªn test set
2. **Application** (Minh PhÃº): XÃ¢y dá»±ng `fraud_detection_app.py` Ä‘á»ƒ sá»­ dá»¥ng models

## Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á»:

1. Kiá»ƒm tra `requirements.txt` Ä‘Ã£ cÃ i Ä‘á»§ thÆ° viá»‡n (Ä‘áº·c biá»‡t `xgboost`)
2. Äáº£m báº£o Ä‘Ã£ cháº¡y notebook 01 trÆ°á»›c Ä‘á»ƒ cÃ³ preprocessed data
3. Kiá»ƒm tra paths vÃ  imports trong notebook
4. Xem láº¡i code examples trong notebook 02

## Code Examples

### Example 1: Train vÃ  Save má»™t Model

```python
from src.models import train_random_forest, save_model
from src.data_preprocessing import get_class_weights

# Get class weights
class_weights = get_class_weights(y_train)

# Train model
model = train_random_forest(
    X_train, y_train,
    n_estimators=200,
    max_depth=15,
    class_weight=class_weights,
    random_state=42
)

# Save model
save_model(model, 'Random Forest', save_dir='models')
```

### Example 2: Load vÃ  Sá»­ dá»¥ng Model

```python
from src.models import load_model

# Load model
model = load_model('Random Forest', model_dir='models')

# Predict
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]
```

### Example 3: ÄÃ¡nh giÃ¡ Model

```python
from src.evaluate import evaluate_model, get_metrics_dict

# Evaluate
metrics, figures = evaluate_model(
    y_test, y_pred, y_pred_proba,
    model_name='Random Forest',
    save_dir='results',
    plot_cm=True,
    plot_roc=True
)

# Get metrics dict
metrics_dict = get_metrics_dict(y_test, y_pred, y_pred_proba, 'Random Forest')
```

---

**ChÃºc báº¡n hoÃ n thÃ nh tá»‘t cÃ´ng viá»‡c!** ğŸš€

